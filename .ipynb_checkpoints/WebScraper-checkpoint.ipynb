{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Web Scraper\n",
    "\n",
    "## Necessary Python Libraries:\n",
    "- Requests\n",
    "- Beautiful Soup\n",
    "    > pip install requests<br />pip install bs4\n",
    "    \n",
    "First we need to import the libraries above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the data from a webpage we will need to do three steps, find our URL, use requests to get the information from the URL, and then use Beautiful Soup to take the url and shape it into content that we can actually use.\n",
    "\n",
    "For the purpose of this notebook I'm just going to retrieve the fights from the latest UFC Pay Per View card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.sherdog.com/events/UFC-246-McGregor-vs-Cerrone-82425'\n",
    "response = requests.get(URL)\n",
    "content = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "print('Completed')\n",
    "\n",
    "# Uncomment below to see all the html code, left out to keep notebook concise.\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need to tell Beautiful Soup what HTML tags our information is contained in, in this case the fighter names are contained in:<br />\n",
    ">\\<span itemprop=\"name\">\n",
    "    \n",
    "We represent this in beautiful soup as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span itemprop=\"name\">UFC 246<br/>McGregor vs. Cerrone</span>, <span itemprop=\"name\">Ultimate Fighting Championship (UFC)</span>, <span itemprop=\"name\">Conor McGregor</span>, <span itemprop=\"name\">Donald Cerrone</span>, <span itemprop=\"name\">Holly Holm</span>, <span itemprop=\"name\">Raquel Pennington</span>, <span itemprop=\"name\">Alexey Oleynik</span>, <span itemprop=\"name\">Maurice Greene</span>, <span itemprop=\"name\">Brian Kelleher</span>, <span itemprop=\"name\">Ode Osbourne</span>, <span itemprop=\"name\">Diego Ferreira</span>, <span itemprop=\"name\">Anthony Pettis</span>, <span itemprop=\"name\">Roxanne Modafferi</span>, <span itemprop=\"name\">Maycee Barber</span>, <span itemprop=\"name\">Sodiq Yusuff</span>, <span itemprop=\"name\">Andre Fili</span>, <span itemprop=\"name\">Askar Askarov</span>, <span itemprop=\"name\">Tim Elliott</span>, <span itemprop=\"name\">Drew Dober</span>, <span itemprop=\"name\">Nasrat Haqparast</span>, <span itemprop=\"name\">Aleksa Camur</span>, <span itemprop=\"name\">Justin Ledet</span>, <span itemprop=\"name\">Sabina Mazo</span>, <span itemprop=\"name\">J.J. Aldrich</span>]\n"
     ]
    }
   ],
   "source": [
    "names = content.find_all('span', attrs={\"itemprop\": \"name\"})\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the name of the fight card as well as the names of all of the fighters. To print out the names we can do so as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UFC 246McGregor vs. Cerrone\n",
      "Ultimate Fighting Championship (UFC)\n",
      "Conor McGregor\n",
      "Donald Cerrone\n",
      "Holly Holm\n",
      "Raquel Pennington\n",
      "Alexey Oleynik\n",
      "Maurice Greene\n",
      "Brian Kelleher\n",
      "Ode Osbourne\n",
      "Diego Ferreira\n",
      "Anthony Pettis\n",
      "Roxanne Modafferi\n",
      "Maycee Barber\n",
      "Sodiq Yusuff\n",
      "Andre Fili\n",
      "Askar Askarov\n",
      "Tim Elliott\n",
      "Drew Dober\n",
      "Nasrat Haqparast\n",
      "Aleksa Camur\n",
      "Justin Ledet\n",
      "Sabina Mazo\n",
      "J.J. Aldrich\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    print(name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this looks a bit ugly, and we don't need to see the first 2 containing UFC 246 and UFC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this once as it continues to delete the first two entries in the list.\n",
    "names = names[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to add some more formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conor McGregor Vs. Donald Cerrone\n",
      "Holly Holm Vs. Raquel Pennington\n",
      "Alexey Oleynik Vs. Maurice Greene\n",
      "Brian Kelleher Vs. Ode Osbourne\n",
      "Diego Ferreira Vs. Anthony Pettis\n",
      "Roxanne Modafferi Vs. Maycee Barber\n",
      "Sodiq Yusuff Vs. Andre Fili\n",
      "Askar Askarov Vs. Tim Elliott\n",
      "Drew Dober Vs. Nasrat Haqparast\n",
      "Aleksa Camur Vs. Justin Ledet\n",
      "Sabina Mazo Vs. J.J. Aldrich\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(names)):\n",
    "    print(names[i].text, end='')\n",
    "    if i % 2 == 0:\n",
    "        print(' Vs. ', end='')\n",
    "    elif i % 2 == 1:\n",
    "        print('\\n', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes / Big Picture\n",
    "The big picture would be to scrape a lot more data than just this (E.g. winner of fight, strikes landed, takedowns, etc.) On top of this it would need to be done for several fight cards at once. However, the process remains the same. Retrieve a url, get the webpage, siphon data from the page, repeat.\n",
    "\n",
    "## High level psuedocode\n",
    "\n",
    "1. Retrieve a webpage that contains all fight cards (E.g. http://www.ufcstats.com/statistics/events/completed?page=all)\n",
    "2. Get Links to each individual fight card from this page\n",
    "3. For each link in links: retrieve the webpage containing all fights on the card\n",
    "4. From the fight card page retrieve a fight_links to each individual fights webpage\n",
    "5. For each fight_link in fight_links: Retrieve webpage of the fight\n",
    "6. Scrape important data (content.find_all command will be used a lot)\n",
    "\n",
    "## Data Storage\n",
    "Something like this could end up being pretty large for a csv, currently think it should be done with a sql database. However, it could still be done with a csv, but might be tricky."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
